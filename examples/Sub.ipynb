{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e503f3ae-d648-44b0-a132-db56ac4fade2",
   "metadata": {},
   "source": [
    "# Produce Simple Star Subtracted Images\n",
    "\n",
    "This script implements a simpler procedure to produce star subtracted images from the \"swarped\" images for a tile.\n",
    "\n",
    "It produces subtracted images using the narrow band filter and the R band filter.\n",
    "\n",
    "The subtractions invoving the N708 filter are just simple subtractions since nominally our swarped images have been\n",
    "adjusted so that the stars are equally bright in all images.\n",
    "\n",
    "The subtraction involving the R band filter is more complicated.  The steps involves removing (to first order) the SII and Ha\n",
    "contaimination to the R band filter, to produce a R band image with only stars, and then subtracting the pure R band image\n",
    "from the SII and H images.  \n",
    "\n",
    "The naming conventions of the various images that are produced should be self explanatory\n",
    "\n",
    "* SII_sub_N708, and Ha_sub_N708 is the images created using N708\n",
    "* SII_sub_R, and Ha_sub_R are the images produced with the R_band\n",
    "* r_sub is the R band images that contains only stars\n",
    "* ha_s2_sub is (or is proportional to) the sum of the Ha and SII emission that was in the R band image\n",
    "\n",
    "There are couple of things to note\n",
    "\n",
    "* The algorithing to do the emission line subtraction from the R band emission can be improved by taking into account the\n",
    "differend fileter widths of the Ha and NII fileters\n",
    "* The routine at the bottom for processing individual fields is not what we want tin the end.  It's a kluge while we \n",
    "are developing a better subtraction algorithm.  It would be better to create the subtracted images immediately after the\n",
    "tiles are swarped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9ce2ac2-d6f2-41dc-85a6-7d1566902e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from glob import glob\n",
    "\n",
    "from astropy.table import Table\n",
    "\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.wcs import WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab4470d1-9468-4fe5-9c42-8a143617099f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../workspace/LMC_c42_d/7/LMC_c42_7.R.t060.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.N708.t400.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.r_sub.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.s2_sub_r.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.R.t008.t060.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.N708.t060.t400.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t030.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.SII.t060.t800.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.ha_s2_sub.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.SII.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.SII.t060.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.R.t008.t060.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.N708.t400.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.SII.t800.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.R.t060.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.ha_sub_r.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t030.t800.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t800.weight.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.N708.t060.t400.fits']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('../workspace/LMC_c42_d/7/L*fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "338c0b54-7658-4f3b-b2a3-1d7c49e7a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ha='../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t030.t800.fits'\n",
    "test_s2='../workspace/LMC_c42_d/7/LMC_c42_7.SII.t060.t800.fits'\n",
    "test_r='../workspace/LMC_c42_d/7/LMC_c42_7.R.t008.t060.fits'\n",
    "test_n708='../workspace/LMC_c42_d/7/LMC_c42_7.N708.t060.t400.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9605f5f2-e73e-4aa1-849a-dfbae591a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_deep_copy(orig):\n",
    "    '''\n",
    "    Make a deep copy of a fits image\n",
    "    \n",
    "    Astropy does not have a way, apparently to make \n",
    "    a deep copy of an image; instead it makes shallow\n",
    "    copies, which means that often one does not know\n",
    "    what one is dealing with. \n",
    "    \n",
    "    The basic problem here is that if one does not\n",
    "    make deep copies, one will not necessary know\n",
    "    what image you are working with, one that is\n",
    "    pristine or one that has been modified\n",
    "    \n",
    "    This little routine\n",
    "    avoids this issue.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    xhead=orig[0].header.copy()\n",
    "    xdata=orig[0].data.copy()\n",
    "    hdu=fits.PrimaryHDU(xdata)\n",
    "    x=fits.HDUList([hdu])\n",
    "    x[0].header=xhead\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "509181fa-a2f2-43bb-8107-9e6cc026ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rband_subtractions(ha,s2,r,outroot=''):\n",
    "    \n",
    "    ha_exists=False\n",
    "    s2_exists=False\n",
    "    r_exists=False\n",
    "\n",
    "    \n",
    "    try:\n",
    "        zha=fits.open(ha)\n",
    "        ha_exists=True\n",
    "    except:\n",
    "        print('The   Ha file could not be openened: %s' % ha)\n",
    "    \n",
    "    try:\n",
    "        zs2=fits.open(s2)\n",
    "        s2_exists=True\n",
    "    except:\n",
    "        print('The  SII file could not be openened: %s' % s2)\n",
    "         \n",
    "    try:\n",
    "        zr=fits.open(r)\n",
    "        r_exists=True\n",
    "    except:\n",
    "        print('The    R file could not be openened: %s' % r)    \n",
    "        \n",
    "    if ha_exists==False or s2_exists==False or r_exists==False:\n",
    "        return\n",
    "    \n",
    "    if outroot=='':\n",
    "        i=ha.rindex('/')\n",
    "        xdir=ha[:i]\n",
    "        xfile=ha[i+1:]\n",
    "\n",
    "        word=xfile.split('.')\n",
    "        outroot=word[0]\n",
    "        outroot='%s/%s' % (xdir,word[0])\n",
    "        # Use the directory path/first_word as the root, which is the usual case\n",
    "\n",
    "    narrow=fits_deep_copy(zha)\n",
    "    narrow[0].data=zha[0].data+zs2[0].data-2*zr[0].data\n",
    "    narrow.writeto(outroot+'.ha_s2_sub.fits',overwrite=True)\n",
    "\n",
    "    r_pure=fits_deep_copy(zr)\n",
    "    r_pure[0].data-= (130/1500)* narrow[0].data\n",
    "    r_pure.writeto(outroot+'.r_sub.fits',overwrite=True)    \n",
    "    \n",
    "    x=fits_deep_copy(zha)\n",
    "    x[0].data-=r_pure[0].data\n",
    "    x.writeto(outroot+'.ha_sub_r.fits',overwrite=True)        \n",
    "\n",
    "    x=fits_deep_copy(zs2)\n",
    "    x[0].data-=r_pure[0].data\n",
    "    x.writeto(outroot+'.s2_sub_r.fits',overwrite=True)      \n",
    "\n",
    "    return\n",
    "\n",
    "make_rband_subtractions(test_ha,test_s2,test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1141e70-f3e2-4a38-8af0-2b914a8954c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n708_subtractions(ha,s2,n708,outroot=''):\n",
    "    '''\n",
    "    For narrow band subtraction we assume there is no emission line\n",
    "    contamination, and since everything is scaled to the same level\n",
    "    we just do a straight subtractin\n",
    "    '''\n",
    "    ha_exists=False\n",
    "    s2_exists=False\n",
    "\n",
    "    n708_exists=False\n",
    "    \n",
    "    try:\n",
    "        zha=fits.open(ha)\n",
    "        ha_exists=True\n",
    "    except:\n",
    "        print('The   Ha file could not be openened: %s' % ha)\n",
    "    \n",
    "    try:\n",
    "        zs2=fits.open(s2)\n",
    "        s2_exists=True\n",
    "    except:\n",
    "        print('The  SII file could not be openened: %s' % s2)\n",
    "      \n",
    "      \n",
    "    try:\n",
    "        zn708=fits.open(n708)\n",
    "        n708_exists=True\n",
    "    except:\n",
    "        print('The N708 file could not be openened: %s' % n708)\n",
    "        return\n",
    "    \n",
    "    if outroot=='':\n",
    "        i=ha.rindex('/')\n",
    "        xdir=ha[:i]\n",
    "        xfile=ha[i+1:]\n",
    "\n",
    "        word=xfile.split('.')\n",
    "        outroot=word[0]\n",
    "        outroot='%s/%s' % (xdir,word[0])\n",
    "        \n",
    "    if ha_exists and n708_exists:\n",
    "        zha[0].data-=zn708[0].data\n",
    "        zha.writeto(outroot+'.ha_sub_n708.fits',overwrite=True)\n",
    "\n",
    "    if s2_exists and n708_exists:\n",
    "        zs2[0].data-=zn708[0].data\n",
    "        zs2.writeto(outroot+'.s2_sub_n708.fits',overwrite=True)\n",
    "        \n",
    "make_n708_subtractions(test_ha,test_s2,test_n708)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f130d04-3032-4a34-8ef5-0ac13d1f7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t030.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.SII.t060.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.R.t008.t060.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.N708.t060.t400.fits')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_files(field='LMC_c42',tile=7,option='all'):\n",
    "    '''\n",
    "    Locate files for creating subtractions in a cell\n",
    "    \n",
    "    This routine is intended to be run from the directory where \n",
    "    the production routines are run, and is something of a kluge\n",
    "    \n",
    "    The options are:\n",
    "    \n",
    "        all - get the files with multiple expsures combined\n",
    "        long - get the files with the a single but the longest exposres\n",
    "        short - get the files with a single and the shorted exposures\n",
    "        \n",
    "    If short and long were not constructed separately with swarp, one\n",
    "    will bet the same result.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    files=glob('../workspace/%s_d/%d/%s_%d.*fits' % (field,tile,field,tile))\n",
    "    # print(files)\n",
    "    \n",
    "    # eliminated the weight files\n",
    "    \n",
    "    xfiles=[]\n",
    "    for one in files:\n",
    "        if one.count('weight')==0 and one.count('sub')==0:\n",
    "            xfiles.append(one)\n",
    "    # print(xfiles)\n",
    "    \n",
    "    times=[]\n",
    "    ntimes=[]\n",
    "    xfilt=[]\n",
    "    for one in xfiles:\n",
    "        words=one.split('/')\n",
    "        \n",
    "        barefile=words[-1]\n",
    "        words=barefile.split('.')\n",
    "        t=0\n",
    "        nt=0\n",
    "        xfilt.append(words[1])\n",
    "        for one in words:\n",
    "            if one[0]=='t':\n",
    "                xt=int(one[1:])\n",
    "                nt+=1\n",
    "                #print(xt)\n",
    "                t+=xt\n",
    "        times.append(t)\n",
    "        ntimes.append(nt)\n",
    "    # print(len(times),times)\n",
    "    # print(len(xfilt),xfilt)\n",
    "    \n",
    "    xtab=Table([xfiles,xfilt,ntimes,times],names=['Filename','Filter','Ntimes','SumT'])\n",
    "    \n",
    "    if option!='all':\n",
    "        xtab=xtab[xtab['Ntimes']==1]\n",
    "    \n",
    "    # print(np.unique(xtab['Filter']))\n",
    "    \n",
    "    ha=xtab[xtab['Filter']=='Ha']\n",
    "    s2=xtab[xtab['Filter']=='SII']\n",
    "    r=xtab[xtab['Filter']=='R']\n",
    "    n708=xtab[xtab['Filter']=='N708']\n",
    "    \n",
    "    # print(len(ha),len(s2),len(r),len(n708))\n",
    "    \n",
    "    if option=='all' or option == 'long':\n",
    "        ha.sort('SumT')\n",
    "        xha=ha[-1]['Filename']\n",
    "        # print(xha)\n",
    "        \n",
    "        s2.sort('SumT')\n",
    "        xs2=s2[-1]['Filename']\n",
    "        \n",
    "        r.sort('SumT')\n",
    "        xr=r[-1]['Filename']\n",
    "        \n",
    "        \n",
    "        n708.sort('SumT')\n",
    "        xn708=n708[-1]['Filename']\n",
    "        \n",
    "    elif option=='short':\n",
    "        ha.sort('SumT')\n",
    "        xha=ha[0]['Filename']\n",
    "\n",
    "        \n",
    "        s2.sort('SumT')\n",
    "        xs2=s2[-1]['Filename']\n",
    "        \n",
    "        r.sort('SumT')\n",
    "        xr=r[-1]['Filename']\n",
    "        \n",
    "\n",
    "        \n",
    "        n708.sort('SumT')\n",
    "        xn708=n708[-1]['Filename']   \n",
    "        \n",
    "    else:\n",
    "        print('Error: Unkown option')\n",
    "        return\n",
    "        \n",
    "    \n",
    "    return xha,xs2,xr,xn708\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "get_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62884f28-90a0-4af8-9535-3e0770aa6774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.SII.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.R.t060.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.N708.t400.fits')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files(option='short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3447f8-9638-4141-a455-423f640bc4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fb12187-715c-4846-b582-65649e9e0cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../workspace/LMC_c42_d/7/LMC_c42_7.Ha.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.SII.t800.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.R.t060.fits',\n",
       " '../workspace/LMC_c42_d/7/LMC_c42_7.N708.t400.fits')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files(option='long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64bcd2f1-e8d2-4f42-b599-cc2b7b7c3ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_tile(field='LMC_c42',tile=7,option='all',root=''):\n",
    "    ha,s2,r,n708=get_files(field,tile,option)\n",
    "    make_rband_subtractions(ha,s2,r,root)\n",
    "    make_n708_subtractions(ha,s2,n708,root)\n",
    "do_one_tile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91174bb5-f170-4e04-a7f6-41412e4fb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_field(field='LMC_c42',option='all',root=''):\n",
    "    i=1\n",
    "    while i<17:\n",
    "        do_one_tile(field,i,option,root)\n",
    "        i+=1\n",
    "\n",
    "do_one_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19e3f531-ee62-47b2-9831-61c13cfe7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_one_field(field='LMC_c45',option='all',root='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ksl]",
   "language": "python",
   "name": "conda-env-ksl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
